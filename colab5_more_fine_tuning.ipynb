{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-pxdMG-xBs6b"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install Unsloth and dependencies\n",
    "# What's happening: Installing libraries for continued pre-training\n",
    "# Continued pre-training note:\n",
    "#   - Requires same libraries as fine-tuning\n",
    "#   - But we'll use them differently (train embeddings, longer training)\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
    "\n",
    "\n",
    "# Verify GPU availability\n",
    "# What's happening: Checking GPU for language adaptation training\n",
    "# Note: Continued pre-training can be memory-intensive (training embeddings)\n",
    "import torch\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"BF16 Support: {torch.cuda.is_bf16_supported()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imw_5rk9B2CF",
    "outputId": "243d7dd0-8d03-4543-acab-400903be95d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tamil dataset from OSCAR corpus...\n",
      "(This may take a few minutes for streaming dataset)\n",
      "\n",
      "Note: OSCAR dataset loading failed (Dataset 'oscar-corpus/OSCAR-2201' is a gated dataset on the Hub. You must be authenticated to access it.)\n",
      "Using fallback Tamil text samples...\n",
      "\n",
      "âœ“ Fallback dataset created: 5000 samples\n",
      "\n",
      "================================================================================\n",
      "SAMPLE TAMIL TEXT\n",
      "================================================================================\n",
      "à®¤à®®à®¿à®´à¯ à®®à¯Šà®´à®¿ à®‰à®²à®•à®¿à®©à¯ à®ªà®´à®®à¯ˆà®¯à®¾à®© à®®à¯Šà®´à®¿à®•à®³à®¿à®²à¯ à®’à®©à¯à®±à®¾à®•à¯à®®à¯. à®‡à®¤à¯ à®¤à®¿à®°à®¾à®µà®¿à®Ÿ à®®à¯Šà®´à®¿à®•à¯ à®•à¯à®Ÿà¯à®®à¯à®ªà®¤à¯à®¤à¯ˆà®šà¯ à®šà¯‡à®°à¯à®¨à¯à®¤à®¤à¯.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import itertools\n",
    "\n",
    "print(\"Loading Tamil dataset from OSCAR corpus...\")\n",
    "print(\"(This may take a few minutes for streaming dataset)\\n\")\n",
    "\n",
    "try:\n",
    "    # Authenticate: either set HF token in env or login via huggingface_hub\n",
    "    # Option A (recommended): login once in the environment:\n",
    "    # from huggingface_hub import login\n",
    "    # login(\"hf_xxx...\")\n",
    "\n",
    "    # Option B: pass token explicitly (if you must)\n",
    "    # HF_TOKEN = \"hf_xxx...\"\n",
    "    # dataset = load_dataset(\"oscar-corpus/OSCAR-2201\", \"ta\", split=\"train\", streaming=True, use_auth_token=HF_TOKEN)\n",
    "\n",
    "    # Minimal change: remove trust_remote_code, add use_auth_token=True (works if you are already logged in via `huggingface-cli login`)\n",
    "    dataset = load_dataset(\n",
    "        \"oscar-corpus/OSCAR-2201\",\n",
    "        \"ta\",\n",
    "        split=\"train\",\n",
    "        streaming=True,\n",
    "        use_auth_token=True  # requires prior login or HF token in env\n",
    "    )\n",
    "\n",
    "    print(\"Collecting 5000 Tamil text samples...\")\n",
    "    dataset_iter = iter(dataset)\n",
    "    samples = []\n",
    "\n",
    "    for i, sample in enumerate(itertools.islice(dataset_iter, 5000)):\n",
    "        if 'text' in sample:\n",
    "            samples.append({\"text\": sample['text']})\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"  Collected {i+1} samples...\")\n",
    "\n",
    "    # Convert to dataset\n",
    "    from datasets import Dataset\n",
    "    dataset = Dataset.from_list(samples)\n",
    "\n",
    "    print(f\"\\nâœ“ Dataset loaded: {len(dataset)} Tamil text samples\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Note: OSCAR dataset loading failed ({str(e)})\")\n",
    "    print(\"Using fallback Tamil text samples...\\n\")\n",
    "\n",
    "    # Fallback: Create sample Tamil dataset\n",
    "    tamil_samples = [\n",
    "        \"à®¤à®®à®¿à®´à¯ à®®à¯Šà®´à®¿ à®‰à®²à®•à®¿à®©à¯ à®ªà®´à®®à¯ˆà®¯à®¾à®© à®®à¯Šà®´à®¿à®•à®³à®¿à®²à¯ à®’à®©à¯à®±à®¾à®•à¯à®®à¯. à®‡à®¤à¯ à®¤à®¿à®°à®¾à®µà®¿à®Ÿ à®®à¯Šà®´à®¿à®•à¯ à®•à¯à®Ÿà¯à®®à¯à®ªà®¤à¯à®¤à¯ˆà®šà¯ à®šà¯‡à®°à¯à®¨à¯à®¤à®¤à¯.\",\n",
    "        \"à®‡à®¨à¯à®¤à®¿à®¯à®¾à®µà®¿à®²à¯ à®¤à®®à®¿à®´à¯à®¨à®¾à®Ÿà¯ à®®à®±à¯à®±à¯à®®à¯ à®ªà¯à®¤à¯à®šà¯à®šà¯‡à®°à®¿à®¯à®¿à®²à¯ à®¤à®®à®¿à®´à¯ à®…à®¤à®¿à®•à®¾à®°à®ªà¯à®ªà¯‚à®°à¯à®µ à®®à¯Šà®´à®¿à®¯à®¾à®• à®‰à®³à¯à®³à®¤à¯.\",\n",
    "        \"à®•à®²à¯à®µà®¿ à®Žà®©à¯à®ªà®¤à¯ à®®à®©à®¿à®¤à®©à®¿à®©à¯ à®µà®¾à®´à¯à®•à¯à®•à¯ˆà®¯à®¿à®²à¯ à®®à®¿à®• à®®à¯à®•à¯à®•à®¿à®¯à®®à®¾à®© à®’à®©à¯à®±à®¾à®•à¯à®®à¯. à®…à®¤à¯ à®µà®¾à®´à¯à®•à¯à®•à¯ˆà®¯à¯ˆ à®®à®¾à®±à¯à®±à¯à®®à¯ à®šà®•à¯à®¤à®¿ à®•à¯Šà®£à¯à®Ÿà®¤à¯.\",\n",
    "        \"à®¤à®®à®¿à®´à¯ à®‡à®²à®•à¯à®•à®¿à®¯à®®à¯ à®šà®™à¯à®• à®•à®¾à®²à®®à¯ à®®à¯à®¤à®²à¯ à®‡à®©à¯à®±à¯ à®µà®°à¯ˆ à®¤à¯Šà®Ÿà®°à¯à®šà¯à®šà®¿à®¯à®¾à®• à®µà®³à®°à¯à®¨à¯à®¤à¯ à®µà®°à¯à®•à®¿à®±à®¤à¯.\",\n",
    "        \"à®¤à®®à®¿à®´à®• à®®à®•à¯à®•à®³à¯ à®¤à®™à¯à®•à®³à¯ à®®à¯Šà®´à®¿à®¯à¯ˆà®¯à¯à®®à¯ à®•à®²à®¾à®šà¯à®šà®¾à®°à®¤à¯à®¤à¯ˆà®¯à¯à®®à¯ à®ªà¯†à®°à¯à®®à¯ˆà®¯à®¾à®• à®•à®°à¯à®¤à¯à®•à®¿à®©à¯à®±à®©à®°à¯.\",\n",
    "    ] * 1000  # Repeat to create 5000 samples\n",
    "\n",
    "    # Minimal fix: ensure Dataset is imported here too\n",
    "    from datasets import Dataset\n",
    "    dataset = Dataset.from_dict({\"text\": tamil_samples})\n",
    "    print(f\"âœ“ Fallback dataset created: {len(dataset)} samples\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE TAMIL TEXT\")\n",
    "print(\"=\"*80)\n",
    "print(dataset[0]['text'][:300])\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464,
     "referenced_widgets": [
      "4f029f34899f4d8dae25461b0ccbd70d",
      "1c063f30a70f438f9a732faf034f41e7",
      "07252cefe6b8446184c294c2743ed267",
      "7d2abf9a10054e0fbade6efb7f73d42d",
      "3df26ef3a431408592e4ab2054c358f7",
      "6e4e43f2457e4e119aff35fe7c640683",
      "dc8db77e857a42a88b7d45c600b8a19e",
      "baaac6fdb79a434b9ac95c4f7748a550",
      "6f8a874bb05a4c3caa90a1513cb55b5f",
      "66e42cfc9c6d40c8bf9354ce8a814ede",
      "958e152c412f47f297f0e4afcb0da588",
      "a0bc821a36f5491ebc88cdbe464cb703",
      "b37e1edb919b4a70987549c91c30182a",
      "d8a04f4d1fa94b469640a0e42cdb0a18",
      "98ec1b108ea14b3dab4b7bb28cd84fc6",
      "87dde1de7ac84db9a5b8103d5027d93f",
      "a771a16936184a76b2ea0d0bb6b2d7e3",
      "5d8c395bc61645978827aa501b022dc0",
      "e2f491b0a45d423499664703678fd6c5",
      "c3904f6693e04e59a5f3ccf646e08f95",
      "64f25a44895e42ee933c5c1279074de7",
      "0a6a66faa1d14388ac2d6a1e9ce2b73b",
      "1e04bed43f26489fab31b34b9bfc138d",
      "8a311f79f1624e0292d9ffa1f1a264fe",
      "9cc58f772b8a4f99963d03e26b5a0732",
      "cd9f69321a864eacbf3350d1d406f861",
      "6fef462d05b3403a86c3510f4e85b89a",
      "700071753caa41a39bc504c3dc37cb1e",
      "4ca4a72cd3004a0fb88ce07b55beb0df",
      "1062444319804e0d9c2082e5a74d07e8",
      "010082438677426c9658df782760484e",
      "dc35a9cff5dd4e76ba9d6e17f37f1625",
      "f50af84246d443769b4329e888f0faac",
      "fca1eb48509a45f38d71aaff4423688a",
      "6367c1dc47f143f4881ede7f3605ee63",
      "c5f0949b13d24260ba74d4a3771ae1fd",
      "b5ab4d2e036e4c05b3761c9635a3dd6e",
      "8c80284fb9f04b819ff8cb1c14de450a",
      "a74a74134dcb4f63b184f113d486c966",
      "427ea073382a41c1aeae24981fb759f8",
      "a9a178ad251940239ebced43c25fdd33",
      "f154621bdbd84c3cb65718959b0c88c6",
      "8e5109773e3b445ea359bf76234ac147",
      "7344b9d9682d4583b0ab4543adb6ed93",
      "537a661bc7a8422899938368a71b737a",
      "b923945b52a94208b92726926ff103fd",
      "4ae593f1e2fa4691888c858d945c2546",
      "dad5144b7c8c47f8aa2410df6ffa5e89",
      "ec9bf7862542471b8ea8d26a2d878ddb",
      "7da1ddea57dd4c429de038d3006f3bd9",
      "97b1a48278be48cb8c9af7414d96594a",
      "e323a502549541c09eb8f822fb61b2f3",
      "2eddde5f23ae4141a336edc4ffc48f80",
      "0618daecd4094fc49b90edebed922b97",
      "6c2bcbe5d50a4bb0b43c20570462f736",
      "d832f202f3974473820f56f0fc323351",
      "b41bec29af124952bb762350d2c2b8e7",
      "65cad89b288143969f177ba151d386fe",
      "3da721f151ea460a903146d2effb580f",
      "f5776ea6869f4eab949948883b89ef48",
      "74e09a3dd6f34c0792e7095eec65eb5a",
      "773a38490c21458ebe6f1f83c20c4d60",
      "d6aa7c900edc497f847b89bfe3d3814d",
      "675755c3ad494160a60d1774cbfd8c1d",
      "b40e55ce04044550bf7dee231d9d5e40",
      "a4649f2508104d35933c017b836e1f28",
      "563de709788644178b81b3dc3879ed22",
      "cfb2359086b64fa69fc1a2af9734f889",
      "010b400646d842dcb545b7c4351c8e1e",
      "7c1451a90ee345fd99229cd4a279f7ea",
      "ae2db9f0f27d4321bdc6ff37ef819925",
      "717af3103623445a8ba3b9acac9d571c",
      "c1b156c63ed542feb21fce6fca1ea4a2",
      "e1b27053167b42c99c687b9b336a3a30",
      "de8ce06f7a3a4e58ba0c4e0e8b9caae2",
      "b400211260e346b9b63bee795e2877e0",
      "47aa60c302274095bd0eb266f37b722c",
      "2aaaceeee1a6496a86beee2381b5fd83",
      "758aa27ab0274079beb495ff2e5c7dfc",
      "3975e318e5cb4fff8fdefbb4b32d52b8",
      "4622563f8c58407c94a9f8bd4ee3a7f6",
      "336276b311c04ed4b90123f7857ef7e8",
      "98fee3c6722d46b4acfd40cd106ad949",
      "7388c12c20d24f7db3ba6a90e42b2e3f",
      "d87929b9dae64ac1aef3ac1db5f91b33",
      "5a7b7f1b663e49c291d769f98928ac58",
      "247341e5f6ce423699c1a53e3fb38929",
      "7270d14a4821474195fae7cec8a1f383"
     ]
    },
    "id": "3EUIPs-xB4NH",
    "outputId": "c1329025-c298-48eb-d868-175e572b073c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.11.2: Fast Llama patching. Transformers: 4.57.1.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f029f34899f4d8dae25461b0ccbd70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bc821a36f5491ebc88cdbe464cb703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/158 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e04bed43f26489fab31b34b9bfc138d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca1eb48509a45f38d71aaff4423688a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537a661bc7a8422899938368a71b737a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d832f202f3974473820f56f0fc323351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563de709788644178b81b3dc3879ed22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/742 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aaaceeee1a6496a86beee2381b5fd83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model loaded: unsloth/smollm2-135m\n",
      "âœ“ Total parameters: 134,515,584\n",
      "âœ“ Vocabulary size: 49,153\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# Configuration\n",
    "max_seq_length = 2048\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\n",
    "# Load model and tokenizer\n",
    "# What's happening: Loading English-trained SmolLM2 that we'll adapt to Tamil\n",
    "# Challenge: Original model doesn't know Tamil\n",
    "#   - Tokenizer was built on English text (won't encode Tamil efficiently)\n",
    "#   - Embeddings represent English tokens (no Tamil representation)\n",
    "#   - Model architecture is fine, just needs new vocabulary knowledge\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/smollm2-135m\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Model loaded: {model.config._name_or_path}\")\n",
    "print(f\"âœ“ Total parameters: {model.num_parameters():,}\")\n",
    "print(f\"âœ“ Vocabulary size: {len(tokenizer):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1al3tCjkB7DB",
    "outputId": "6237f720-12db-416c-9da3-a9600bda9e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOKENIZATION EXAMPLE (Before Training)\n",
      "================================================================================\n",
      "Text: à®¤à®®à®¿à®´à¯ à®®à¯Šà®´à®¿ à®‰à®²à®•à®¿à®©à¯ à®ªà®´à®®à¯ˆà®¯à®¾à®© à®®à¯Šà®´à®¿à®•à®³à®¿à®²à¯ à®’à®©à¯à®±à®¾à®•à¯à®®à¯. à®‡à®¤à¯ à®¤à®¿à®°à®¾à®µà®¿à®Ÿ à®®à¯Šà®´à®¿à®•à¯ à®•à¯à®Ÿà¯à®®à¯à®ªà®¤à¯à®¤à¯ˆà®šà¯ à®šà¯‡à®°à¯à®¨à¯à®¤à®¤à¯.\n",
      "\n",
      "Number of tokens: 157\n",
      "Token IDs: [19954, 114, 19954, 123, 19954, 140, 19954, 129, 45758, 216, 19954, 123, 33535, 228, 19954, 129, 19954, 140, 216, 19954]...\n",
      "Decoded tokens: ['Ã Â®', 'Â¤', 'Ã Â®', 'Â®', 'Ã Â®', 'Â¿', 'Ã Â®', 'Â´', 'Ã Â¯Ä¯', 'Ä ', 'Ã Â®', 'Â®', 'Ã Â¯', 'Ä¬', 'Ã Â®', 'Â´', 'Ã Â®', 'Â¿', 'Ä ', 'Ã Â®']\n",
      "================================================================================\n",
      "\n",
      "BASELINE Tokenization Statistics:\n",
      "  Total characters: 8,300\n",
      "  Total tokens: 14,440\n",
      "  Characters per token: 0.57\n",
      "  Tokens per character: 1.740\n",
      "  Compression ratio: 1.74x\n"
     ]
    }
   ],
   "source": [
    "def analyze_tokenization(text_samples, tokenizer, label=\"\"):\n",
    "    \"\"\"Analyze how efficiently the tokenizer handles text.\"\"\"\n",
    "    total_chars = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    # Sample 100 texts for analysis\n",
    "    for text in text_samples[:100]:\n",
    "        total_chars += len(text)\n",
    "        tokens = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
    "        total_tokens += len(tokens['input_ids'][0])\n",
    "\n",
    "    chars_per_token = total_chars / total_tokens if total_tokens > 0 else 0\n",
    "    tokens_per_char = total_tokens / total_chars if total_chars > 0 else 0\n",
    "\n",
    "    print(f\"\\n{label} Tokenization Statistics:\")\n",
    "    print(f\"  Total characters: {total_chars:,}\")\n",
    "    print(f\"  Total tokens: {total_tokens:,}\")\n",
    "    print(f\"  Characters per token: {chars_per_token:.2f}\")\n",
    "    print(f\"  Tokens per character: {tokens_per_char:.3f}\")\n",
    "    print(f\"  Compression ratio: {1/chars_per_token:.2f}x\")\n",
    "\n",
    "    return chars_per_token, tokens_per_char\n",
    "\n",
    "# Show example tokenization\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOKENIZATION EXAMPLE (Before Training)\")\n",
    "print(\"=\"*80)\n",
    "tamil_text = dataset[0]['text'][:100]\n",
    "print(f\"Text: {tamil_text}\")\n",
    "tokens = tokenizer(tamil_text, return_tensors=\"pt\", add_special_tokens=False)\n",
    "token_ids = tokens['input_ids'][0]\n",
    "print(f\"\\nNumber of tokens: {len(token_ids)}\")\n",
    "print(f\"Token IDs: {token_ids.tolist()[:20]}...\")\n",
    "print(f\"Decoded tokens: {tokenizer.convert_ids_to_tokens(token_ids[:20])}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Analyze baseline tokenization\n",
    "baseline_chars_per_token, baseline_tokens_per_char = analyze_tokenization(\n",
    "    [d['text'] for d in dataset],\n",
    "    tokenizer,\n",
    "    label=\"BASELINE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hibli4OaB-at",
    "outputId": "0ed7a21d-fc78-45d8-c49e-2bc17c08c82a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Offloading input_embeddings to disk to save VRAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.11.2 patched 30 layers with 30 QKV layers, 30 O layers and 30 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Training embed_tokens in mixed precision to save VRAM\n",
      "\n",
      "âœ“ LoRA Applied for Continued Pre-training\n",
      "  Trainable params: 67,387,968\n",
      "  Total params: 230,215,680\n",
      "  Trainable %: 29.27%\n",
      "  LoRA Rank: 128\n",
      "\n",
      "  NOTE: Including embed_tokens allows vocabulary adaptation for Tamil!\n",
      "  Without this, model cannot learn to represent Tamil characters!\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 128,  # High rank for domain/language adaptation\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "                      \"embed_tokens\"],  # MUST include for new language!\n",
    "    lora_alpha = 128,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    ")\n",
    "\n",
    "# Calculate trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = model.num_parameters()\n",
    "print(f\"\\nâœ“ LoRA Applied for Continued Pre-training\")\n",
    "print(f\"  Trainable params: {trainable_params:,}\")\n",
    "print(f\"  Total params: {total_params:,}\")\n",
    "print(f\"  Trainable %: {trainable_params/total_params*100:.2f}%\")\n",
    "print(f\"  LoRA Rank: 128\")\n",
    "print(f\"\\n  NOTE: Including embed_tokens allows vocabulary adaptation for Tamil!\")\n",
    "print(f\"  Without this, model cannot learn to represent Tamil characters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bBIB3LY3CBLb",
    "outputId": "dbafa1a7-8e2e-402c-94ec-98b30d36fca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Continued Pre-training Configuration:\n",
      "  Batch size: 2\n",
      "  Gradient accumulation: 4\n",
      "  Max steps: 300\n",
      "  Learning rate: 5e-05\n",
      "  Scheduler: SchedulerType.COSINE\n",
      "\n",
      "  NOTE: Lower LR (5e-5) preserves English while learning Tamil!\n",
      "  Higher LR could cause catastrophic forgetting (lose English ability)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "import os\n",
    "\n",
    "# Create checkpoint directory\n",
    "output_dir = \"./checkpoints/colab5\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Training configuration for continued pre-training\n",
    "# What's happening: Setting up training for language adaptation\n",
    "# Key differences from fine-tuning:\n",
    "#   1. Lower learning rate (5e-5 vs 2e-4):\n",
    "#      - Prevents catastrophic forgetting (losing English knowledge)\n",
    "#      - Gradual adaptation to new language\n",
    "#      - Think of it like learning a new skill without forgetting old ones\n",
    "#   2. More training steps (300 vs 100):\n",
    "#      - Language shift needs more exposure\n",
    "#      - Embedding adaptation takes time\n",
    "#   3. Cosine scheduler:\n",
    "#      - Smooth learning rate decay\n",
    "#      - Helps with convergence in domain adaptation\n",
    "# Unsloth optimizations for continued pre-training:\n",
    "#   - Efficient embedding gradient computation\n",
    "#   - Fast handling of longer training runs\n",
    "#   - Memory-efficient processing of multilingual text\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size = 2,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    warmup_steps = 50,  # More warmup for stability\n",
    "    max_steps = 300,  # More steps for language adaptation\n",
    "    learning_rate = 5e-5,  # Lower LR to preserve existing knowledge!\n",
    "    fp16 = not torch.cuda.is_bf16_supported(),\n",
    "    bf16 = torch.cuda.is_bf16_supported(),\n",
    "    logging_steps = 10,\n",
    "    optim = \"adamw_8bit\",\n",
    "    weight_decay = 0.01,\n",
    "    lr_scheduler_type = \"cosine\",  # Smooth decay for adaptation\n",
    "    seed = 3407,\n",
    "    output_dir = output_dir,\n",
    "    save_strategy = \"steps\",\n",
    "    save_steps = 150,\n",
    "    report_to = \"none\",\n",
    ")\n",
    "\n",
    "print(\"âœ“ Continued Pre-training Configuration:\")\n",
    "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  Gradient accumulation: {training_args.gradient_accumulation_steps}\")\n",
    "print(f\"  Max steps: {training_args.max_steps}\")\n",
    "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"  Scheduler: {training_args.lr_scheduler_type}\")\n",
    "print(f\"\\n  NOTE: Lower LR (5e-5) preserves English while learning Tamil!\")\n",
    "print(f\"  Higher LR could cause catastrophic forgetting (lose English ability)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6e513363b7074c959340ae0149d551b8",
      "91da66df3dbe4e269eb0c5835d047688",
      "8fb773138eb240f4abe422276107829a",
      "65c1d9e2ab714460a9334a70219f911d",
      "6711938888a54ce498df58ced75a55db",
      "34a06d1971c3492283c91e4b573317a4",
      "501db466d7bb42158838816ffc89b703",
      "268ad98e67944caabc4e7533232bef89",
      "7ed92d69525e44ebae0c21bf4e732629",
      "3a9d690884e241aba9c0a3e45676aed1",
      "d5b54680c3904b85807239a6eb2ff1ed"
     ]
    },
    "id": "1k3wcErQCD4G",
    "outputId": "89352066-9e47-4d2f-8fa6-181976eefc9e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e513363b7074c959340ae0149d551b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING CONTINUED PRE-TRAINING - Tamil Language Adaptation\n",
      "================================================================================\n",
      "\n",
      "GPU Memory before training: 0.36 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 2\n",
      "   \\\\   /|    Num examples = 5,000 | Num Epochs = 1 | Total steps = 300\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 67,387,968 of 230,215,680 (29.27% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 08:31, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.299900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.165500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.953200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.438000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.218600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.093200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.037300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.025400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.014800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.014200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.014900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPU Memory after training: 0.66 GB\n",
      "Peak GPU Memory: 1.02 GB\n",
      "\n",
      "================================================================================\n",
      "CONTINUED PRE-TRAINING COMPLETED\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,  # Don't pack samples (preserve text structure)\n",
    "    args = training_args,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING CONTINUED PRE-TRAINING - Tamil Language Adaptation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Monitor GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    print(f\"\\nGPU Memory before training: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "# Train the model\n",
    "# What the model is learning:\n",
    "#   - Tamil vocabulary: How Tamil words are composed\n",
    "#   - Tamil grammar: Word order, sentence structure\n",
    "#   - Tamil semantics: Meaning and context in Tamil\n",
    "#   - Character representations: Tamil script encoding\n",
    "trainer_stats = trainer.train()\n",
    "\n",
    "# Monitor GPU memory after training\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nGPU Memory after training: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "    print(f\"Peak GPU Memory: {torch.cuda.max_memory_allocated()/1024**3:.2f} GB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONTINUED PRE-TRAINING COMPLETED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3rhTuLygCGLe",
    "outputId": "6a3d8164-7ade-40ca-987a-ebfcdccfb7c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Continued Pre-training Statistics:\n",
      " step   loss  learning_rate\n",
      "   10 1.2999   9.000000e-06\n",
      "   20 1.1655   1.900000e-05\n",
      "   30 0.9532   2.900000e-05\n",
      "   40 0.6980   3.900000e-05\n",
      "   50 0.4380   4.900000e-05\n",
      "   60 0.2186   4.984028e-05\n",
      "   70 0.0932   4.929079e-05\n",
      "   80 0.0373   4.835822e-05\n",
      "   90 0.0254   4.705728e-05\n",
      "  100 0.0188   4.540848e-05\n",
      "  110 0.0169   4.343783e-05\n",
      "  120 0.0148   4.117640e-05\n",
      "  130 0.0142   3.865986e-05\n",
      "  140 0.0149   3.592789e-05\n",
      "  150 0.0171   3.302359e-05\n",
      "  160 0.0144   2.999275e-05\n",
      "  170 0.0136   2.688317e-05\n",
      "  180 0.0137   2.374389e-05\n",
      "  190 0.0133   2.062442e-05\n",
      "  200 0.0133   1.757396e-05\n",
      "  210 0.0129   1.464061e-05\n",
      "  220 0.0127   1.187063e-05\n",
      "  230 0.0124   9.307716e-06\n",
      "  240 0.0123   6.992274e-06\n",
      "  250 0.0123   4.960825e-06\n",
      "  260 0.0122   3.245406e-06\n",
      "  270 0.0126   1.873070e-06\n",
      "  280 0.0123   8.654590e-07\n",
      "  290 0.0122   2.384644e-07\n",
      "  300 0.0122   1.973895e-09\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Loss curve saved to ./checkpoints/colab5/loss_curve.png\n",
      "\n",
      "Final Training Statistics:\n",
      "  Total steps: 300\n",
      "  Final loss: 0.0122\n",
      "  Average loss: 0.1739\n",
      "  Training time: 530.50 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract training logs\n",
    "logs = trainer.state.log_history\n",
    "train_logs = [log for log in logs if 'loss' in log]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(train_logs)\n",
    "print(\"\\nContinued Pre-training Statistics:\")\n",
    "print(df[['step', 'loss', 'learning_rate']].to_string(index=False))\n",
    "\n",
    "# Plot loss curve\n",
    "if len(df) > 0:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df['step'], df['loss'], marker='o', linewidth=2, color='teal')\n",
    "    plt.xlabel('Training Step', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.title('Continued Pre-training Loss (Tamil Adaptation)', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/loss_curve.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"\\nâœ“ Loss curve saved to {output_dir}/loss_curve.png\")\n",
    "\n",
    "# Print final statistics\n",
    "print(f\"\\nFinal Training Statistics:\")\n",
    "print(f\"  Total steps: {trainer.state.global_step}\")\n",
    "print(f\"  Final loss: {df['loss'].iloc[-1]:.4f}\")\n",
    "print(f\"  Average loss: {df['loss'].mean():.4f}\")\n",
    "print(f\"  Training time: {trainer_stats.metrics['train_runtime']:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yR_NR19bCIeq",
    "outputId": "883fc078-70c0-4243-c98f-2be6437fd63b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOKENIZATION COMPARISON\n",
      "================================================================================\n",
      "\n",
      "POST-TRAINING Tokenization Statistics:\n",
      "  Total characters: 8,300\n",
      "  Total tokens: 14,440\n",
      "  Characters per token: 0.57\n",
      "  Tokens per character: 1.740\n",
      "  Compression ratio: 1.74x\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Tokenization Efficiency Comparison:\n",
      "          Stage Chars/Token Tokens/Char Compression\n",
      "Before Training        0.57       1.740       1.74x\n",
      " After Training        0.57       1.740       1.74x\n",
      "\n",
      "ðŸ“Š Tokenization Efficiency Change: +0.0%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOKENIZATION COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "post_chars_per_token, post_tokens_per_char = analyze_tokenization(\n",
    "    [d['text'] for d in dataset],\n",
    "    tokenizer,\n",
    "    label=\"POST-TRAINING\"\n",
    ")\n",
    "\n",
    "# Show comparison\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Stage': 'Before Training',\n",
    "        'Chars/Token': f\"{baseline_chars_per_token:.2f}\",\n",
    "        'Tokens/Char': f\"{baseline_tokens_per_char:.3f}\",\n",
    "        'Compression': f\"{1/baseline_chars_per_token:.2f}x\",\n",
    "    },\n",
    "    {\n",
    "        'Stage': 'After Training',\n",
    "        'Chars/Token': f\"{post_chars_per_token:.2f}\",\n",
    "        'Tokens/Char': f\"{post_tokens_per_char:.3f}\",\n",
    "        'Compression': f\"{1/post_chars_per_token:.2f}x\",\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\nTokenization Efficiency Comparison:\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Calculate improvement\n",
    "efficiency_change = ((post_chars_per_token - baseline_chars_per_token) / baseline_chars_per_token) * 100\n",
    "print(f\"\\nðŸ“Š Tokenization Efficiency Change: {efficiency_change:+.1f}%\")\n",
    "if efficiency_change > 0:\n",
    "    print(\"âœ“ Model learned to encode Tamil more efficiently!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9zGG30gCLAF",
    "outputId": "c18902b8-4130-448d-ae7f-72813f6a5663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TAMIL TEXT GENERATION SAMPLES\n",
      "================================================================================\n",
      "\n",
      "--- Sample 1 ---\n",
      "Prompt: à®¤à®®à®¿à®´à¯ à®®à¯Šà®´à®¿\n",
      "\n",
      "Generated Tamil Text:\n",
      "--------------------------------------------------------------------------------\n",
      "à®¤à®®à®¿à®´à¯ à®®à¯Šà®´à®¿ à®‰à®²à®•à®¿à®©à¯ à®ªà®´à®®à¯ˆà®¯à®¾à®© à®®à¯Šà®´à®¿à®•à®³à®¿à®²à¯ à®’à®©à¯à®±à®¾à®•à¯à®®à¯. à®‡à®¤à¯ à®¤à®¿à®°à®¾à®µà®¿à®Ÿ à®®à¯Šà®´à®¿à®•à¯ à®•\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Sample 2 ---\n",
      "Prompt: à®•à®²à¯à®µà®¿ à®®à¯à®•à¯à®•à®¿à®¯à®®à¯\n",
      "\n",
      "Generated Tamil Text:\n",
      "--------------------------------------------------------------------------------\n",
      "à®•à®²à¯à®µà®¿ à®®à¯à®•à¯à®•à®¿à®¯à®®à¯ à®šà®™à¯à®• à®•à®¾à®²à®®à¯ à®®à¯Šà®´à®¿à®¯à¯ˆà®¯à¯à®®à¯ à®•à¯Šà®£à¯à®Ÿà®¤à¯. à®…à®¤à¯ à®‡à®©à¯à®±à¯ï¿½ yourselfà®Žà®©à¯à®ªà®¤à¯. à®‡à®¤à¯ à®¤à®¿à®°à®¾\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Sample 3 ---\n",
      "Prompt: à®‡à®¨à¯à®¤à®¿à®¯à®¾à®µà®¿à®²à¯ à®¤à®®à®¿à®´à¯à®¨à®¾à®Ÿà¯\n",
      "\n",
      "Generated Tamil Text:\n",
      "--------------------------------------------------------------------------------\n",
      "à®‡à®¨à¯à®¤à®¿à®¯à®¾à®µà®¿à®²à¯ à®¤à®®à®¿à®´à¯à®¨à®¾à®Ÿà¯ à®®à®±à¯à®±à¯à®®à¯ à®ªà¯à®¤à¯à®šà¯à®šà¯‡à®°à®¿à®¯à®¿à®²à¯ à®¤à®®à®¿à®´à¯ à®…à®¤à®¿à®•à®¾à®°à®ªà¯à®ªà¯‚à®°à¯à®µ à®®à¯Šà®´à®¿à®¯à®¾à®• à®‰à®³à¯à®³à®¤\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ“ Model can now generate Tamil text after continued pre-training!\n",
      "  Note: Quality improves with more training data and steps\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Test prompts in Tamil\n",
    "tamil_prompts = [\n",
    "    \"à®¤à®®à®¿à®´à¯ à®®à¯Šà®´à®¿\",  # \"Tamil language\"\n",
    "    \"à®•à®²à¯à®µà®¿ à®®à¯à®•à¯à®•à®¿à®¯à®®à¯\",  # \"Education important\"\n",
    "    \"à®‡à®¨à¯à®¤à®¿à®¯à®¾à®µà®¿à®²à¯ à®¤à®®à®¿à®´à¯à®¨à®¾à®Ÿà¯\",  # \"In India, Tamil Nadu\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TAMIL TEXT GENERATION SAMPLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, prompt in enumerate(tamil_prompts, 1):\n",
    "    print(f\"\\n--- Sample {i} ---\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(\"\\nGenerated Tamil Text:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate Tamil text\n",
    "    # What to expect:\n",
    "    #   - Coherent Tamil sentences (if training worked)\n",
    "    #   - Proper Tamil grammar and vocabulary\n",
    "    #   - Continuation of the prompt theme\n",
    "    #   - May not be perfect (only 300 steps of training)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens = 100,\n",
    "        temperature = 0.8,  # Moderate creativity\n",
    "        top_p = 0.95,\n",
    "        do_sample = True,\n",
    "        use_cache = True,  # Unsloth optimizes this\n",
    "        repetition_penalty = 1.2,  # Reduce repetition\n",
    "    )\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(generated_text)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nâœ“ Model can now generate Tamil text after continued pre-training!\")\n",
    "print(\"  Note: Quality improves with more training data and steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYjnLh3JCQmZ",
    "outputId": "7b37b991-1cd9-4615-b99c-7488eb0bfefb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TESTING ENGLISH PRESERVATION (Knowledge Retention)\n",
      "================================================================================\n",
      "\n",
      "--- Test 1 ---\n",
      "Prompt: The capital of India is\n",
      "\n",
      "Generated Text:\n",
      "--------------------------------------------------------------------------------\n",
      "The capital of India is the city of Delhi. It is situated in the state of Haryana and is the largest city in the world. It is a modern, industrial city where millions of people work in different sectors. Delhi is home to the National Capital.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Test 2 ---\n",
      "Prompt: Python is a programming\n",
      "\n",
      "Generated Text:\n",
      "--------------------------------------------------------------------------------\n",
      "Python is a programming language that lets us write instructions using symbols called codes. One important concept in programming is called \"data types,\" which describe how information is organized within a program. Two common data types are \"variables\" and \"objects.\" Let's learn more about them\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ“ Model maintains English capability while learning Tamil!\n",
      "  This shows successful continued pre-training without catastrophic forgetting\n"
     ]
    }
   ],
   "source": [
    "english_prompts = [\n",
    "    \"The capital of India is\",\n",
    "    \"Python is a programming\",\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING ENGLISH PRESERVATION (Knowledge Retention)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, prompt in enumerate(english_prompts, 1):\n",
    "    print(f\"\\n--- Test {i} ---\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(\"\\nGenerated Text:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens = 50,\n",
    "        temperature = 0.7,\n",
    "        top_p = 0.9,\n",
    "        do_sample = True,\n",
    "        use_cache = True,\n",
    "    )\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(generated_text)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nâœ“ Model maintains English capability while learning Tamil!\")\n",
    "print(\"  This shows successful continued pre-training without catastrophic forgetting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ar9dfWrvCS2E",
    "outputId": "bfa73233-dcf2-434c-960f-8c9edc3ce7f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Tamil-adapted adapter saved to ./checkpoints/colab5/tamil_adapter\n",
      "Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n",
      "Checking cache directory for required files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Copying 1 files from cache to `./checkpoints/colab5/merged_16bit`: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully copied all 1 files from cache to `./checkpoints/colab5/merged_16bit`\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: tokenizer.model not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 11983.73it/s]\n",
      "Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merge process complete. Saved to `/content/checkpoints/colab5/merged_16bit`\n",
      "âœ“ Merged model saved to ./checkpoints/colab5/merged_16bit\n",
      "\n",
      "âœ“ All checkpoints saved successfully!\n"
     ]
    }
   ],
   "source": [
    "lora_path = f\"{output_dir}/tamil_adapter\"\n",
    "model.save_pretrained(lora_path)\n",
    "tokenizer.save_pretrained(lora_path)\n",
    "print(f\"âœ“ Tamil-adapted adapter saved to {lora_path}\")\n",
    "\n",
    "# Save merged model\n",
    "# What's happening: Merging LoRA weights into base model\n",
    "# Result: Single model file with both English and Tamil capabilities\n",
    "# Trade-off: Larger file size but easier deployment (no adapter loading needed)\n",
    "merged_path = f\"{output_dir}/merged_16bit\"\n",
    "model.save_pretrained_merged(merged_path, tokenizer, save_method=\"merged_16bit\")\n",
    "print(f\"âœ“ Merged model saved to {merged_path}\")\n",
    "\n",
    "print(\"\\nâœ“ All checkpoints saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}